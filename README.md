# Road Network Extraction using Satellite Imagery
MoveHack Global Mobility Hackathon 2018

Original Image             |Mask generated by the model|Mask overlaid on original  |
:-------------------------:|:-------------------------:|:-------------------------:|
![](assets/o.png?raw=true) |![](assets/m.png?raw=true) |![](assets/n.png?raw=true) |


### Table of Contents
0. [About](#about)
0. [Dataset Summary](#massachusetts-roads-dataset-summary)
0. [Installation](#installation)
0. [Quick start](#quick-start)

### About
In this work, we implement the U-Net segmentation architecture on the Mnih et. al. Massachusetts Roads Dataset for the tak of road network extraction. The trained model scores a mask accuracy of 96% on the test set.

### Massachusetts Roads Dataset Summary
The Massachusetts Roads Dataset by Mnih et. al. is freely available at [here](https://www.cs.toronto.edu/~vmnih/data/). There is also a torrent link available [here](http://academictorrents.com/details/3b17f08ed5027ea24db04f460b7894d913f86c21).It is recommended to download the dataset from this link.

| Description | Size  | Files  |
| --- | --- | --- |  
|mass_roads/train | 9.5GB | 1108 |
|mass_roads/valid | 150MB | 14   |
|mass_roads/test  | 450MB | 49   |

### Installation
The following installation has been tested on MacOSX 10.3.3 and Ubuntu 16.04

1. Clone the repo. (NOTE: This repo requires Python 3.6)
```bash
git clone https://github.com/akshaybhatia10/RoadNetworkExtraction-MoveHack.git
```

2. The project requires the fastai library. To install it, simply run the setup.sh script. (OPTIONAL: The default installation is for CPU. To install for GPU, in setup.sh file, change conda env update -f environment-cpu.yml
to conda env update.)
```bash
chmod 777 setup.sh
./setup.sh
```
3. To train the road network extraction, download the dataset from [here](http://academictorrents.com/details/3b17f08ed5027ea24db04f460b7894d913f86c21)
 or [here](https://www.cs.toronto.edu/~vmnih/data/). For running the pretrained model, proceed without this step.


### Quick start

You have 2 options

1. Train: To train the model on the dataset, make sure to download the dataset and follow the repo structure as:


```
The results folder contains the following info
```angular2html
RoadNetworkExtraction-MoveHack
|_ mass_roads/
|  |_ train/
|  |  |_sat/
|  |  |  |img1.tiff
|  |  |  |img2.tiff
|  |  |  |......
|  |  |_map/
|  |  |  |img2.tif
|  |  |  |img2.tif
|  |  |  |......
|  |_ valid/
|  |  |_sat/
|  |  |  |img1.tiff
|  |  |  |img2.tiff
|  |  |  |......
|  |  |_map/
|  |  |  |img2.tif
|  |  |  |img2.tif
|  |  |  |......
|  |_ test/
|  |  |_sat/
|  |  |  |img1.tiff
|  |  |  |img2.tiff
|  |  |  |......
|  |  |_map/
|  |  |  |img2.tif
|  |  |  |img2.tif
|  |  |  |......
|_ fastai
|_ dataset.py
|_ model.py
|_ models/
|_ ....
|_ (other files)
```
Now, start training with the following command (This will first set up the necessary folders and convert .tiff files to png and save them. Then it will start trained the u-net model for num_epochs(default is 1) and with cycle_len(default is 4). The trained model wiil be saved to models/.
The final score(mask accuracy) should test set reaches 96%.)

```bash
python main.py --mode train

usage: main.py  [--data_dir] [--learning_rate] [--mode]
                [--model_dir] [--num_epoch] [--cycle_len]
                [--test_img]

optional arguments:
  --learning_rate        config yaml file
  --model_dir            model file dir
  --test_img             test image for inference
  --num_epoch            number of epcohs
  --cycle_len            cycle len
```

2. Test: To test the pretrained model (with mask accuracy score of 96%).

```bash
python main.py --mode test --test_img test_images/
```

This will save 3 different images the the current folder- 1024x1024 version of original images, 1024x1024 generated mask image(output of the model), 1024x1024 mask overlayed on original image.

